{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Memory Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/khannatanmai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safely remove the selected drive\n",
      "['safely', 'remove', 'the', 'selected', 'drive']\n"
     ]
    }
   ],
   "source": [
    "input_line = input()\n",
    "\n",
    "#tokenise\n",
    "candidate_tokens = word_tokenize(input_line)\n",
    "\n",
    "print(candidate_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Source TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tm_tokenized = [] #Tokenized TM SRC\n",
    "\n",
    "with open('./tm_data/src_tm_500.txt') as src_tm:\n",
    "    line = src_tm.readline()\n",
    "    \n",
    "    while line:\n",
    "        tokens = word_tokenize(line)\n",
    "        src_tm_tokenized.append(tokens)\n",
    "        line = src_tm.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Safely', 'remove', 'the', 'selected', 'drive'] 1\n",
      "['To', 'control', 'the', 'sap-sucking', 'insect'] 4\n",
      "['Thow', 'art', 'the', 'Mighty'] 4\n",
      "['In', 'the', 'desert', 'continent'] 4\n",
      "['Make', 'the', 'selected', 'text', 'uppercase'] 4\n"
     ]
    }
   ],
   "source": [
    "edit_distance_all = []\n",
    "N = 5 #Top N matches returned\n",
    "\n",
    "for element in src_tm_tokenized:\n",
    "    ed = nltk.edit_distance(candidate_tokens, element)\n",
    "    edit_distance_all.append(ed)\n",
    "    \n",
    "#Get top N results\n",
    "edit_distance_all = np.array(edit_distance_all)\n",
    "\n",
    "sorted_indices = np.argsort(edit_distance_all) #Sorts in ascending order and returns the indices of elements in original array\n",
    "least_N_indices = sorted_indices[:N] #We want least edit distance\n",
    "\n",
    "for i in least_N_indices:\n",
    "    print(src_tm_tokenized[i], edit_distance_all[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval of Target from TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "चयनित ड्राइव सुरक्षित रूप से निकालें\n",
      "\n",
      "रस-चूसक कीट पर काबू पाने के लिए\n",
      "\n",
      "\n",
      "\n",
      "रेगिस्तान महाद्वीप में\n",
      "\n",
      "निश्चित आईकन को लचीला बनाएँ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tgt_tm_array = []\n",
    "\n",
    "with open('./tm_data/tgt_tm_500.txt') as tgt_tm:\n",
    "    line = tgt_tm.readline()\n",
    "    \n",
    "    while line:\n",
    "        tgt_tm_array.append(line)\n",
    "        line = tgt_tm.readline()\n",
    "        \n",
    "for i in least_N_indices:\n",
    "    print(tgt_tm_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
