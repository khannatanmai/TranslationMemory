{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Memory Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/khannatanmai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please safely remove the drive\n",
      "['Please', 'safely', 'remove', 'the', 'drive']\n"
     ]
    }
   ],
   "source": [
    "input_line = input()\n",
    "\n",
    "#tokenise\n",
    "candidate_tokens = word_tokenize(input_line)\n",
    "\n",
    "print(candidate_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Source TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tm_tokenized = [] #Tokenized TM SRC\n",
    "\n",
    "with open('../tm_data/tm_src_10000_pp.txt') as src_tm:\n",
    "    line = src_tm.readline()\n",
    "    \n",
    "    while line:\n",
    "        tokens = word_tokenize(line)\n",
    "        src_tm_tokenized.append(tokens)\n",
    "        line = src_tm.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['safely', 'remove', 'selected', 'drive'] 2\n",
      "['mercy', 'upon', 'remove', 'calamity', 'befallen'] 4\n",
      "['5.1', 'identify', 'remove', 'unwanted', 'materials'] 4\n",
      "['“', 'safely', 'boarded', 'ship', 'say'] 4\n",
      "['remove', 'cough'] 4\n"
     ]
    }
   ],
   "source": [
    "edit_distance_all = []\n",
    "N = 5 #Top N matches returned\n",
    "\n",
    "for element in src_tm_tokenized:\n",
    "    ed = nltk.edit_distance(candidate_tokens, element)\n",
    "    edit_distance_all.append(ed)\n",
    "    \n",
    "#Get top N results\n",
    "edit_distance_all = np.array(edit_distance_all)\n",
    "\n",
    "sorted_indices = np.argsort(edit_distance_all) #Sorts in ascending order and returns the indices of elements in original array\n",
    "least_N_indices = sorted_indices[:N] #We want least edit distance\n",
    "\n",
    "for i in least_N_indices:\n",
    "    print(src_tm_tokenized[i], edit_distance_all[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval of Target from TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "चयनित ड्राइव सुरक्षित रूप से निकालें\n",
      "\n",
      "यदि हम (किसी आज़माइश में डालने के पश्चात) उनपर दया करते और जिस तकलीफ़ में वे होते उसे दूर कर देते तो भी वे अपनी सरकशी में हठात बहकते रहते\n",
      "\n",
      "5.1 अनावश्यक सामग्री की पहचान किस प्रकार करें और उसे हटाएँ\n",
      "\n",
      "फिर जब तू नौका पर सवार हो जाए और तेरे साथी भी तो कह\n",
      "\n",
      "कब्ज को दूर करने के लिए पका हुआ बेल खाने से आराम मिलता है ।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tgt_tm_array = []\n",
    "\n",
    "with open('../tm_data/tm_tgt_10000.txt') as tgt_tm:\n",
    "    line = tgt_tm.readline()\n",
    "    \n",
    "    while line:\n",
    "        tgt_tm_array.append(line)\n",
    "        line = tgt_tm.readline()\n",
    "        \n",
    "for i in least_N_indices:\n",
    "    print(tgt_tm_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
